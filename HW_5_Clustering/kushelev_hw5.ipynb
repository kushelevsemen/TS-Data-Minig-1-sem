{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №5 - Алгоритмы кластеризации\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <hr\\>\n",
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 17 декабря 2018, 06:00 <br\\>\n",
    "**Штраф за опоздание:** -2 балла после 06:00 17 декабря, -4 балла после 06:00 24 декабря, -6 баллов после 06:00 31 декабря -8 баллов  после 06:00 7 января\n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания.\n",
    "<hr\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Из чего состоит задание:**\n",
    "\n",
    "###### Теоретические вопросы (2 балла)\n",
    "\n",
    "###### Реализация алгоритма кластеризации (6 баллов)\n",
    "\n",
    "###### Боевое применение (2 балла)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw4.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определяем, что вам досталось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Укажите свою фамилию на русском языке в поле ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Имплементируйте алгоритм кластеризации Hierarchical clustering с поддержкой single-linkage, complete-linkage, average-linkage (параметры - число кластеров, linkage)\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "def lucky_hash(text):\n",
    "    return int(hashlib.md5(text.encode('utf-8')).hexdigest()[:8], 16) \n",
    "\n",
    "USER_NAME = u\"Иванов\".lower()\n",
    "\n",
    "ALGORITHMS = [\n",
    "    u\"Gaussian Mixture Model с использованием maximum a-posteriori для выбора кластера (параметр - число кластеров)\",\n",
    "    u\"Hierarchical clustering с поддержкой single-linkage, complete-linkage, average-linkage (параметры - число кластеров, linkage)\",]\n",
    "\n",
    "print (\"Имплементируйте алгоритм кластеризации %s\"\\\n",
    "% (\n",
    "    ALGORITHMS[lucky_hash(USER_NAME[::-1]) % 2]\n",
    ") )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не стоит переживать из-за Вашего варианта. Технически оба алгоритма несложно реализовать.  EM алгоритма бояться не стоит, Вам будет нужно просто реализовать уже выведенные формулы для E и M шагов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "The pycodestyle_magic extension is already loaded. To reload it, use:\n",
      "  %reload_ext pycodestyle_magic\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.spatial as ss\n",
    "import sklearn.cluster as sc\n",
    "import sklearn.manifold as sm\n",
    "import sklearn.datasets as ds\n",
    "import sklearn.metrics as smt\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,5)\n",
    "\n",
    "# Plotting config\n",
    "%pylab inline\n",
    "\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теоретическое введение\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная задача кластерного анализа — разбиение исходного набора объектов на группы (кластеры) таким образом, чтобы объекты в группе были похожи друг на друга, а объекты из разных групп - отличались. \n",
    "\n",
    "В этой работе мы будем реализовывать один из двух популярных методов кластеризации: разделение смеси нормальных распределений или агломеративную кластеризацию. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Смесь нормальных распределений\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Предполагаем, что наши данные порождены смесью $k$ нормальных распределений, то есть \n",
    "\n",
    "$$ p(\\mathbf{x}) = \\sum_k \\pi_k \\mathcal{N}(\\mathbf{x} | \\mathbf{\\mu}_k, \\mathbf{\\Sigma}_k) $$,\n",
    "\n",
    "\n",
    "где $\\mathcal{N}$ - многомерное нормальное распределение размерности ${D}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\\mathcal{N(\\mathbf{x} | \\mathbf{\\mu}, \\mathbf{\\Sigma}}) = \\frac{1}{(2 \\pi)^{D/2}} \\frac{1}{|\\mathbf{\\Sigma}|^{1/2}} \\exp \\left\\{-\\frac{1}{2}(\\mathbf{x} - \\mathbf{\\mu})^T \\mathbf{\\Sigma^{-1}} (\\mathbf{x} - \\mathbf{\\mu})\\right\\}$$\n",
    "\n",
    "**Параметры**  \n",
    "\n",
    "\n",
    "${D}$-мерный вектор средних\n",
    "\n",
    "$$\\mathbf{\\mu}$$\n",
    "\n",
    "$D \\times D$-мерная матрица ковариации   (симметричная)\n",
    "\n",
    "\n",
    "$$\\mathbf{\\Sigma} = E[(\\mathbf{x} - \\mathbf{\\mu})(\\mathbf{x} - \\mathbf{\\mu})^T]$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Необходимо оценить параметры $\\pi_k, \\mathbf{\\mu_k}, \\mathbf{\\Sigma_k} $ для всех компонент смеси.  Сделать это можно с помощью EM алгоритма - алгоритма, который находит оценку максимального правдоподобия в задаче со скрытыми переменными. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectation Maximization\n",
    "\n",
    "**I** До цикла проинциализировать случайно  $\\mu_k, \\Sigma_k, \\pi_k$ ($\\pi_k$ должны суммироваться в 1)\n",
    "\n",
    "**E** Expectation: при фиксированных $\\mu_k, \\Sigma_k, \\pi_k$\n",
    "$$\n",
    "p(z_k = 1| x_n ) = \\gamma(z_{nk}) = \\frac{\\pi_k \\mathcal{N} (\\mathbf{x}_n | \\mu_k, \\Sigma_k)}{\\sum_{j=1}^K \\pi_j \\mathcal{N} (\\mathbf{x}_n | \\mu_j, \\Sigma_j)}\n",
    "$$\n",
    "**M** Maximization: при фиксированных $\\gamma(z_{nk})$\n",
    "$$\n",
    "N_k = \\sum_{n=1}^N \\gamma(z_{nk}), \\;\\; \\mu_k = \\frac 1 {N_k} \\sum_{n=1}^N \\gamma(z_{nk}) \\mathbf{x}_n\n",
    "$$\n",
    "$$\n",
    "\\Sigma_k = \\frac 1 {N_k} \\sum_{n=1}^N \\gamma(z_{nk}) (\\mathbf{x}_n - \\mu_k)(\\mathbf{x}_n - \\mu_k)^T\n",
    "$$\n",
    "$$\n",
    "\\pi_k = \\frac{N_k}{N}\n",
    "$$\n",
    "**S** Остановиться при достижении сходимости"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Номер кластера для $n$ объекта будем брать по принципу maximum a-posteriori, то есть относить объект к тому кластеру, у которого максимальна апостериорная вероятность:\n",
    "$$ k_n =  \\arg\\underset{k}\\max  p(z_k = 1| x_n ) =  \\arg\\underset{k}\\max \\gamma(z_{nk}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Агломеративная кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иерархические алгоритмы кластеризации строят на выборке систему вложенных разбиений.  Наиболее часто испоьзуемые иерархические алгоритмы - агломеративные алгоритмы, которые строят ирархию по восходящей, то есть от момента, когда все элементы являются отдельными кластерами, до того момента, пока вся выборка не станет одним кластером."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сам алгоритм описать можно примерно так:\n",
    "\n",
    "* начинаем с ситуации, когда каждый объект - отдельный кластер\n",
    "* на каждом шаге совмещаем два наиболее близких кластера\n",
    "* останавливаемся, когда получаем требуемое количество или единственный кластер"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "В данной работе Вам предлагается реализовать три варианта расстояний между кластерами, по которым Вы определяете пару для слияния: \n",
    "* Single linkage\n",
    "$$ d_{min}(C_i, C_j) = \\min_{\\mathbf{x} \\in C_i, \\mathbf{x}' \\in C_j} \\|\\mathbf{x} -\\mathbf{x}' \\| $$\n",
    "\n",
    "* Complete linkage\n",
    "$$ d_{max}(C_i, C_j) = \\max_{\\mathbf{x} \\in C_i, \\mathbf{x}' \\in C_j} \\|\\mathbf{x} -\\mathbf{x}' \\| $$\n",
    "\n",
    "* Average linkage\n",
    "$$ d_{avg}(C_i, C_j) = \\frac{1}{n_i n_j}\\sum_{\\mathbf{x} \\in C_i}\\sum_{\\mathbf{x}' \\in C_j} \\|\\mathbf{x} -\\mathbf{x}' \\| $$\n",
    "\n",
    "Для простоты будем использовать евклидово расстояние между объектами.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того, чтобы на втором этапе нам не пересчитывать заново расстояния между всеми парами кластеров, можно использовать Формулы Ланса-Вильямса, которые позволяют посчитать расстояние между кластерами после объединения, используя только расстояния между кластерами до объедения.  Таким образом, достаточно будет посчитать расстояния только между всеми одноэлементными кластерами (первый этап), а затем пересчитывать расстояния при их объединении через \n",
    "формулы Ланса-Вильямса. \n",
    "\n",
    "Общая  формула выглядит так:\n",
    "$$ d(C_i \\cup C_j, C_k) = a_i \\cdot d(C_i, C_k) + a_j \\cdot d(C_j, C_k) + b \\cdot d(C_i, C_j) + c \\cdot |d(C_i, C_k) - d(C_j, C_k)|$$\n",
    "\n",
    "Можно показать, что все относительно разумные кластерные расстояния можно описать данной формулой. \n",
    "\n",
    "Для интересущих нас linkage:\n",
    "\n",
    "* single-linkage       $a_i = \\frac{1}{2}, a_j =  \\frac{1}{2}, b = 0, c =  - \\frac{1}{2} $\n",
    "\n",
    "* complete-linkage     $a_i = \\frac{1}{2}, a_j =  \\frac{1}{2}, b = 0, c =   \\frac{1}{2} $\n",
    "\n",
    "* average-linkage       $a_i = \\frac{|C_i|}{|C_i \\cup C_j|}, a_j =  \\frac{|C_j|}{|C_i \\cup C_j|}, b = 0, c = 0 $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теоретические вопросы (2 балла)\n",
    "В этой части Вам будут предложены теоретичские вопросы и задачи по теме. Вы, конечно, можете списать их у своего товарища или найти решение в интернете, но учтите, что они обязательно войдут в теоретический коллоквиум. Лучше разобраться в теме сейчас и успешно ответить на коллоквиуме, чем списать, не разобравшись в материале, и быть терзаемым совестью. \n",
    "\n",
    "\n",
    "Формулы надо оформлять в формате **LaTeX**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 1. Сходимость kmeans.\n",
    "\n",
    "Метод kmeans является частным случаем EM алгоритма и наиболее простым в обосновании сходимости. Докажите, что kmeans всегда сходится, и итераций не будет превышать $k^N$, где $k$ $-$ число кластеров, $N$ $-$ число объектов\n",
    "\n",
    "Подсказка: Вам стоит рассмотреть функционал, который минимизирует алгоритм, и подумать, как он изменяется на E шаге и на M шаге.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Решение***\n",
    "\n",
    "Рассмотрим функционал $$L(C) = \\sum_k \\sum_{i \\in C_k} ||x_i - \\mu_k||^2$$\n",
    "\n",
    "E шаг:\n",
    "\n",
    "При фиксированных $C_k$ функционал достигает минимума при $\\mu_k$ равном среднему (решение задачи МНК в в скалярном случае).\n",
    "\n",
    "M шаг:\n",
    "\n",
    "Каждый $x_i$ переопределяется к классу, центроид которого ближе всего к нему. Значит, функционал не возрастает.\n",
    "\n",
    "Число разбиений $N$ точек на $k$ кластеров равно $k^N$. Если на какой-то итерации $L(C^{(i-1)})=L(C^{(i)})$, центроиды не обновятся и алгоритм остановится. Такое состояние будет гарантировано достигнуто за $k^N$ итераций."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 2. Сходимость EM.\n",
    "\n",
    "Разобравшись со сходимостью kmeans, можно догадаться и до ответа про EM алгоритм.\n",
    "\n",
    "При каком условии на правдоподобие системы EM алгоритм будет  сходиться?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Решение***\n",
    "\n",
    "На каждой итерации EM-алгоритма полное правдоподобие системы не убывает.\n",
    "\n",
    "Поэтому, если правдоподобие ограничено сверху, то алгоритм сойдется (куда-нибудь)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача 3. Формулы Ланса-Вильямса.\n",
    "\n",
    "Формулы Ланса-Вильямса крайне удобны для быстрого пересчта расстояний в агломеративной кластеризации. Давайте докажем  формулы для single и complete linkage. \n",
    "\n",
    "Докажите, что:\n",
    "\n",
    "$d_{\\min}(U \\cup V, S) = \\frac{1}{2} d_{\\min}(U, S) + \\frac{1}{2} d_{\\min}(V, S)  - \\frac{1}{2} | d_{\\min}(U, S) - d_{\\min}(V, S) |  $\n",
    "\n",
    "\n",
    "$d_{\\max}(U \\cup V, S) = \\frac{1}{2} d_{\\max}(U, S) + \\frac{1}{2} d_{\\max}(V, S)  + \\frac{1}{2} | d_{\\max}(U, S) - d_{\\max}(V, S) |  $\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Решение***\n",
    "\n",
    "Single linkage:\n",
    "\n",
    "$d_{min}(A, B) = min_{a \\in A, b \\in B}||a-b||$\n",
    "\n",
    "$d_{min}(U \\cup V, S) = min(d_{min}(U, S), d_{min}(V, S))$\n",
    "\n",
    "Пусть min достигается на $x \\in U, s \\in S$.\n",
    "\n",
    "Тогда $d_{min}(U \\cup V, S) = d_{min}(U, S)$ и $d_{min}(U, S) <= d_{min}(V, S)$\n",
    "\n",
    "$|d_{min}(U, S)-d_{min}(V, S)| = d_{min}(U, S) - d_{min}(V, S)$\n",
    "\n",
    "И $d_{min}(U \\cup V, S) = d_{min}(U, S)$.\n",
    "\n",
    "Аналогично, если  $x \\in V, s \\in S$.\n",
    "\n",
    "Те же приемы для complete linkage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализация алгоритма кластеризации  (6 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм кластеризации должен удовлетворять следующему интерфейсу. Конструктор принимает набор параметров, необходимых для работы алгоритма кластеризации. Метод `fit` подсчитывает параметры модели и возвращает `self`. Метод `predict` возвращает вектор с индексами кластеров для поданных в него объектов `x`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClusterMixin\n",
    "from sklearn.metrics.pairwise import euclidean_distances as dist\n",
    "\n",
    "\n",
    "class Clustering(BaseEstimator, ClusterMixin):\n",
    "    \"\"\"\n",
    "    Implement clustering algorithm according\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k=2, algorithm='single'):\n",
    "        \"\"\"\n",
    "        Please add necessary algoritm parameters to class constructor.\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.algorithm = algorithm\n",
    "        if self.algorithm == 'single':\n",
    "            self.linkage = self.single_linkage\n",
    "        elif self.algorithm == 'complete':\n",
    "            self.linkage = self.complete_linkage\n",
    "        else:\n",
    "            print('Unknown linkage type')\n",
    "        return\n",
    "\n",
    "    def single_linkage(self, i, j):\n",
    "        d_i = self.dist_matrix[i]\n",
    "        d_j = self.dist_matrix[j]\n",
    "        self.dist_matrix[i] = 0.5 * d_i + 0.5 * d_j - 0.5 * np.abs(d_i - d_j)\n",
    "        # Теперь в матрице расстояний новому кластеру\n",
    "        # соответствует i строка и столбец.\n",
    "        # Inf запрещает обращаться к столбцу и строке j\n",
    "        # (они больше не соответвуют никакому кластеру)\n",
    "        self.dist_matrix[j] = np.inf\n",
    "        self.dist_matrix[:, j] = np.inf\n",
    "        # Если возникла неопределенность в новом столбце\n",
    "        # (из-за арифметики с Inf),\n",
    "        # принудительно ставим Inf,\n",
    "        # ведь это столбец/строка по построению соответствуют\n",
    "        # удаленным кластерам или расстоянию объекта до себя.\n",
    "        for elem in range(self.N):\n",
    "            if np.isnan(self.dist_matrix[i, elem]):\n",
    "                self.dist_matrix[i, elem] = np.inf\n",
    "        self.dist_matrix[:, i] = self.dist_matrix[i]\n",
    "\n",
    "    def complete_linkage(self, i, j):\n",
    "        d_i = self.dist_matrix[i]\n",
    "        d_j = self.dist_matrix[j]\n",
    "        self.dist_matrix[i] = 0.5 * d_i + 0.5 * d_j + 0.5 * np.abs(d_i - d_j)\n",
    "        self.dist_matrix[j] = np.inf\n",
    "        self.dist_matrix[:, j] = np.inf\n",
    "        for elem in range(self.N):\n",
    "            if np.isnan(self.dist_matrix[i, elem]):\n",
    "                self.dist_matrix[i, elem] = np.inf\n",
    "        self.dist_matrix[:, i] = self.dist_matrix[i]\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Use data matrix x to compute model parameters\n",
    "        \"\"\"\n",
    "        self.N = len(X)\n",
    "        # Список, элементы которого - номера объектов в кластере.\n",
    "        self.clusters = [[x] for x in range(self.N)]\n",
    "        self.dist_matrix = dist(X)\n",
    "        # Inf гарантирует нам, что не возьмем расстояния объекта до себя.\n",
    "        np.fill_diagonal(self.dist_matrix, np.inf)\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Using computed model parameters predict cluster\n",
    "        for all objects from x\n",
    "        \"\"\"\n",
    "        iter = 1\n",
    "        while iter <= self.N - self.k:\n",
    "            ind = np.argmin(self.dist_matrix)\n",
    "            i = ind // self.dist_matrix.shape[0]\n",
    "            j = ind % self.dist_matrix.shape[0]\n",
    "            if i > j:\n",
    "                tmp = i\n",
    "                i = j\n",
    "                j = tmp\n",
    "            iter += 1\n",
    "            # Список, элементы которого - номера объектов в кластере.\n",
    "            # None - значит кластер пустой.\n",
    "            # Не удаляю кластеры, чтобы не ломать нумерцию объектов\n",
    "            # (матрица расстояний не меняет размер)\n",
    "            self.clusters[i] += self.clusters[j]\n",
    "            self.clusters[j] = None\n",
    "            self.linkage(i, j)\n",
    "        # Убираю пустые кластеры\n",
    "        for l in range(self.N - self.k):\n",
    "            self.clusters.remove(None)\n",
    "        y_pred = np.zeros([x.shape[0]])\n",
    "        for C in range(len(self.clusters)):\n",
    "            for x in self.clusters[C]:\n",
    "                y_pred[x] = C\n",
    "        return y_pred.astype(int)\n",
    "\n",
    "    def fit_predict(self, X, y=None):\n",
    "        self.fit(X, y)\n",
    "        return self.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала проверим реализованный алгоритм кластеризации на классическом наборе данных [Iris](http://www.wikiwand.com/en/Iris_flower_data_set). Загрузим данные (они включены в библиотеку sklearn) и посмотрим на то, как они выглядят в двух проекциях (для простоты используем 2 класса из 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "iris = ds.load_iris()\n",
    "x_iris = iris.data[:100]\n",
    "y_iris = iris.target[:100]\n",
    "\n",
    "pl.figure(figsize=(10, 5))\n",
    "\n",
    "pl.subplot(1, 2, 1)\n",
    "pl.scatter(x_iris[:, 0], x_iris[:, 1], c=y_iris, cmap=pl.cm.PuOr, lw=0, s=30)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "\n",
    "pl.subplot(1, 2, 2)\n",
    "pl.scatter(x_iris[:, 2], x_iris[:, 3], c=y_iris, cmap=pl.cm.PuOr, lw=0, s=30)\n",
    "plt.xlabel('Petal length')\n",
    "plt.ylabel('Petal width')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что классы разделяются, поэтому можно надеяться, что наш алгоритм \"найдет\" кластеры, соответствующие исходным классам. Результат работы реализованного алгоритма кластеризации предлагается сравнить с эталонной кластеризацией. Для этого предлагается изучить метрику ([adjusted rand score](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.adjusted_rand_score.html)). В случае если значение этой метрики отличается от 1, предлагается поработать над улучшением реализации своего алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand index for iris is: 1.00\n",
      "My Clustering time is: 0.03454017639160156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/semen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    }
   ],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "my_clust = Clustering()\n",
    "start = time.time()\n",
    "pred_iris = my_clust.fit_predict(x_iris)\n",
    "timer = time.time() - start\n",
    "print(\"Adjusted Rand index for iris is: %.2f\"\n",
    "      % smt.adjusted_rand_score(y_iris, pred_iris))\n",
    "print(f\"My Clustering time is: {timer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM score 1.0. GMM time 0.009765625. AGGL score 1.0. AGGL time 0.0008988380432128906\n"
     ]
    }
   ],
   "source": [
    "# Давайте проверим, как справляются sklearn реализации\n",
    "sklearn_gmm = GaussianMixture(n_components=2)\n",
    "gmm_t0 = time.time()\n",
    "sklearn_gmm.fit(x_iris)\n",
    "gmm_diff = time.time() - gmm_t0\n",
    "gmm_score = smt.adjusted_rand_score(y_iris, sklearn_gmm.predict(x_iris))\n",
    "\n",
    "sklearn_aggl = AgglomerativeClustering(n_clusters=2)\n",
    "aggl_t0 = time.time()\n",
    "aggl_pred = sklearn_aggl.fit_predict(x_iris)\n",
    "aggl_diff = time.time() - aggl_t0\n",
    "aggl_score = smt.adjusted_rand_score(y_iris, aggl_pred)\n",
    "print (\"GMM score {}. GMM time {}. AGGL score {}. AGGL time {}\".format(gmm_score, gmm_diff, aggl_score, aggl_diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сверьте Ваш алгоритм с этими числами. Уверен, что у Вас получится не хуже!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Боевое применение (2  балла)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Алгоритмы кластеризации прекрасны тем, что они позволяют быстро понять, как устроены наши данные. Давайте применим Ваш алгоритм для анализа реальной задачи!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важное замечание: в этой части задания студенту самому предлагается разобраться с данными и их форматом в качестве полезного упраженения. Не принимайте это близко к сердцу :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ввозьмем датасет различных стран.  \n",
    "Данные нужно скачать тут https://data.worldbank.org/data-catalog/world-development-indicators.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подход следующий: фиксируем год, для каждой страны берём индикаторы по зафиксированному году, кластеризуем по индикаторам. \n",
    "Разбиение должно быть объяснимым, в противном случае, скорее всего нужно лучше настроить параметры кластеризации.   \n",
    "\n",
    "Необходимо показать, какие страны попали в общий кластер в и объяснить из-за каких признаков это произошло. Если страны были в одном кластере, а спустя несколько лет разъехались по разным кластерам, попробуйте это объяснить. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Место для Вашего кластерного анализа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country Name</th>\n",
       "      <th>Country Code</th>\n",
       "      <th>Indicator Name</th>\n",
       "      <th>Indicator Code</th>\n",
       "      <th>1960</th>\n",
       "      <th>1961</th>\n",
       "      <th>1962</th>\n",
       "      <th>1963</th>\n",
       "      <th>1964</th>\n",
       "      <th>1965</th>\n",
       "      <th>...</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>Unnamed: 62</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arab World</td>\n",
       "      <td>ARB</td>\n",
       "      <td>2005 PPP conversion factor, GDP (LCU per inter...</td>\n",
       "      <td>PA.NUS.PPP.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arab World</td>\n",
       "      <td>ARB</td>\n",
       "      <td>2005 PPP conversion factor, private consumptio...</td>\n",
       "      <td>PA.NUS.PRVT.PP.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country Name Country Code  \\\n",
       "0   Arab World          ARB   \n",
       "1   Arab World          ARB   \n",
       "\n",
       "                                      Indicator Name     Indicator Code  1960  \\\n",
       "0  2005 PPP conversion factor, GDP (LCU per inter...      PA.NUS.PPP.05   NaN   \n",
       "1  2005 PPP conversion factor, private consumptio...  PA.NUS.PRVT.PP.05   NaN   \n",
       "\n",
       "   1961  1962  1963  1964  1965     ...       2009  2010  2011  2012  2013  \\\n",
       "0   NaN   NaN   NaN   NaN   NaN     ...        NaN   NaN   NaN   NaN   NaN   \n",
       "1   NaN   NaN   NaN   NaN   NaN     ...        NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "   2014  2015  2016  2017  Unnamed: 62  \n",
       "0   NaN   NaN   NaN   NaN          NaN  \n",
       "1   NaN   NaN   NaN   NaN          NaN  \n",
       "\n",
       "[2 rows x 63 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('WDIData.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country Name', 'Country Code', 'Indicator Name', 'Indicator Code',\n",
       "       '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
       "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
       "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
       "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
       "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
       "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
       "       '2014', '2015', '2016', '2017', 'Unnamed: 62'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(422400, 63)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38332, 3)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.loc[:, ['Country Name', 'Indicator Name', '1960']]\n",
    "df1 = df1.dropna()\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130302, 3)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.loc[:, ['Country Name', 'Indicator Name', '2017']]\n",
    "df2 = df2.dropna()\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 403)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1.pivot(index='Country Name', columns='Indicator Name', values='1960')\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 1014)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.pivot(index='Country Name', columns='Indicator Name', values='2017')\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.fillna(0, inplace=True)\n",
    "df2.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df1.values\n",
    "X2 = df2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/semen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in subtract\n",
      "/home/semen/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    }
   ],
   "source": [
    "clust = Clustering(k=20, algorithm='complete')\n",
    "y1 = clust.fit_predict(X1)\n",
    "y2 = clust.fit_predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,\n",
       "        0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  2,  0,  0,  0,  0,  0,  1,  0,  3,  0,  4,  0,  5,  0,  6,  7,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  8,  0,  0,  0,  9,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10,  0,  0,\n",
       "        0,  8,  8,  0,  0,  0,  0, 11, 12, 13,  0,  0,  0,  0,  0,  0, 14,\n",
       "        0,  0,  0,  0,  0, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0, 16,  0,  6,  0,  0,  0,  0,  8,  0,  0,  0,  0,  0,  0,  7,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0, 17,  8,  0,  0, 10,  0,  0,  0,  0,  0,\n",
       "        0,  0,  7,  0,  1,  0,  0, 10,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  2,  0,  0,  7,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 18,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0, 19,  0,  0,  0])"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        1,  2,  0,  0,  0,  0,  0,  0,  0,  3,  4,  5,  0,  2,  0,  2,  2,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  6,  0,  0,  0,  0,  0,  0,  0,\n",
       "        2,  0,  0,  0,  0,  0,  0,  7,  8,  9, 10,  0,  0,  0,  0,  0, 11,\n",
       "        0,  2,  0,  0,  0, 12,  0,  0,  0,  7,  0,  0,  0,  0,  0,  0, 13,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  2,  0,  0,  0,  0,  0,  0,  0,  2,  0,  0,  0, 14,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0, 14,  0,  0,  0,  0,  0,  0,  0,  2,  0,\n",
       "        0,  0, 15,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 16,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 14,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,  0, 17,  0,\n",
       "        0, 18,  0,  0, 19,  0,  0,  0])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Afghanistan', 'Albania', 'American Samoa', 'Andorra', 'Angola',\n",
      "       'Antigua and Barbuda', 'Arab World', 'Argentina', 'Armenia', 'Aruba',\n",
      "       ...\n",
      "       'Uruguay', 'Uzbekistan', 'Vanuatu', 'Venezuela, RB', 'Vietnam',\n",
      "       'Virgin Islands (U.S.)', 'West Bank and Gaza', 'Yemen, Rep.', 'Zambia',\n",
      "       'Zimbabwe'],\n",
      "      dtype='object', name='Country Name', length=226)\n",
      "Index(['Algeria', 'Benin', 'Chad', 'Philippines', 'South Africa', 'Sweden'], dtype='object', name='Country Name')\n",
      "Index(['Bangladesh', 'Cameroon', 'Senegal'], dtype='object', name='Country Name')\n",
      "Index(['Chile'], dtype='object', name='Country Name')\n",
      "Index(['Colombia'], dtype='object', name='Country Name')\n",
      "Index(['Congo, Dem. Rep.'], dtype='object', name='Country Name')\n",
      "Index(['Costa Rica', 'Mexico'], dtype='object', name='Country Name')\n",
      "Index(['Cote d'Ivoire', 'Myanmar', 'Paraguay', 'Sierra Leone'], dtype='object', name='Country Name')\n",
      "Index(['Euro area', 'IBRD only', 'IDA & IBRD total', 'Low & middle income',\n",
      "       'Middle income', 'North America'],\n",
      "      dtype='object', name='Country Name')\n",
      "Index(['European Union'], dtype='object', name='Country Name')\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    print(df1[y1 == k].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Afghanistan', 'Albania', 'Algeria', 'American Samoa', 'Andorra',\n",
      "       'Angola', 'Antigua and Barbuda', 'Arab World', 'Argentina', 'Armenia',\n",
      "       ...\n",
      "       'United States', 'Upper middle income', 'Uruguay', 'Vanuatu',\n",
      "       'Venezuela, RB', 'Virgin Islands (U.S.)', 'West Bank and Gaza',\n",
      "       'Yemen, Rep.', 'Zambia', 'Zimbabwe'],\n",
      "      dtype='object', name='Country Name', length=230)\n",
      "Index(['Cambodia', 'Russian Federation', 'Uganda'], dtype='object', name='Country Name')\n",
      "Index(['Cameroon', 'Congo, Dem. Rep.', 'Costa Rica', 'Cote d'Ivoire',\n",
      "       'Hungary', 'Kazakhstan', 'Madagascar', 'Mexico', 'Mongolia',\n",
      "       'Pakistan'],\n",
      "      dtype='object', name='Country Name')\n",
      "Index(['Chile'], dtype='object', name='Country Name')\n",
      "Index(['China'], dtype='object', name='Country Name')\n",
      "Index(['Colombia'], dtype='object', name='Country Name')\n",
      "Index(['Guinea'], dtype='object', name='Country Name')\n",
      "Index(['India', 'Lao PDR'], dtype='object', name='Country Name')\n",
      "Index(['Indonesia'], dtype='object', name='Country Name')\n",
      "Index(['Iran, Islamic Rep.'], dtype='object', name='Country Name')\n"
     ]
    }
   ],
   "source": [
    "for k in range(10):\n",
    "    print(df2[y2 == k].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Честно говоря, ничего не понял. Получается разреженный предикт, то есть все сваливается в один кластер. Может, оно и правильно, так как я заполнил пропуски нулями, а их было очень много (потому что я очень грубо и бездумно сформировал датасет). Сказать нечего, кроме того, что алгоритм не падает и дает нужное число кластеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Не переживайте, мне тоже было тяжело разобраться с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Контрольные вопросы\n",
    "Постарайтесь максимально развернуто и честно ответить на вопросы. Они охватывают тему алгоритмов кластеризации и скорее нужны преподавателям, чтобы понимать, что именно Вы усвоили плохо. Надеюсь, они подскажут, что именно в теме Вы не понимаете или наоборот порадают, что Вы все знаете ^_^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Опишите, пожалуйста, для каких прикладных задач Вы бы стали использовать методы кластеризации?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ответ***\n",
    "\n",
    "Для того, чтобы изучить структуру данных. В проекте я хотел использовать следующий подход: кластеризовать текстовые документы (в виде tf-idf) и в качестве признаков использовать метки кластера, а мешки слов выкинуть. Не получилось, но подход имеет право на существование."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Какие преимущества и недостатки Вы видите у следуюших алгоритмов кластеризации: kmeans, dbscan, агломеративная кластеризация?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ответ***\n",
    "\n",
    "K-means: быстрый, простой, всегда сходится, но кластеры имеют сферическую форму\n",
    "\n",
    "dbscan: работает для любой формы, сам определяет число кластеров, но не справляется с кластерами разной плотности\n",
    "\n",
    "агломеративная кластеризация: может использовать специальные метрики, любое число кластеров \"из коробки\", но требовательна к ресурсам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* На лекции было показано, что EM алгоритм находит оценку максимального правдоподобия в задаче со сккрытыми переменными. Из курса мат. статистики Вы можете знать, оценка максимального правдоподобия \"оптимальная\" во многих смыслах. В каких же случаях тогда не следует применять метод максимального правдоподобия?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ответ***\n",
    "\n",
    "Делаются серьезные допущения относительно распределения исследуемых величин. Если не знаем структуру распределения, может не стоит использовать EM?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Многие алгоритмы анализа данных страдают \"проклятием\" размерности. Страдают ли этим проклятием алгоритмы кластеризации? Если да, то как бы Вы с этим боролись?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ответ***\n",
    "\n",
    "Страдают. Все изученные нами алгоритмы кластеризации - метрические, а вычисление расстояний в пространствах больших размерностей - дорого. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Представьте, что у Вас есть набор текстовых документов, и Вы хотите разбить эти документы на тематики - новости, спорт, кулинария, кино и так далее. Размеченной выборки у Вас нет, только сами тексты документов. Какие алгоритмы и какие признаки Вы бы использовали для решения данной задачи?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ответ***\n",
    "\n",
    "На мой взгляд тут важнее именно признаки, а не метод кластеризации. Если темы такие, что их разумно определять по словам, а не по смыслу, то можно преобразовать тексты tf-idf и использовать иерархическую кластеризацию с текстовыми нормами (ужасающая размерность). Можно попробовать самому выделить ключевые слова, one-hot-encoding, вхождения этих слов использовать как признаки. Или не самому, а с помощью какого-нибудь статистического критерия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Теперь представьте, что небольшая часть Ваших текстов была размечена людьми, но большая часть так и осталась без таргета. Смогли ли бы Вы использовать эти данные для улучения качества кластеризации? (эта задача называется semi-supervised learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ответ***\n",
    "\n",
    "Использовать для валидации модели. \n",
    "\n",
    "На мой взгляд, любая дополнительная априорная информация это полезно, но как именно ее применять я не вижу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** ВАШ ОТЗЫВ ЗДЕСЬ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отличный курс, все круто! Спасибо!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
